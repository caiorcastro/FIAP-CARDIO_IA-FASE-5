{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CardioIA - Fase 5: Ir Além 1 - Extração de Informações com IA Generativa\n",
                "\n",
                "## Objetivo\n",
                "Utilizar técnicas de Prompt Engineering e a API do **Google Gemini** para transformar anotações médicas desestruturadas em dados estruturados (JSON), facilitando a interoperabilidade e análise de dados."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install google-generativeai python-dotenv pandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import google.generativeai as genai\n",
                "from dotenv import load_dotenv\n",
                "import pandas as pd\n",
                "\n",
                "# Carrega API KEY do .env (certifique-se que o arquivo .env está na pasta raiz ou ajustado aqui)\n",
                "load_dotenv('../.env') \n",
                "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
                "\n",
                "if not api_key:\n",
                "    print(\"ERRO: Chave GEMINI_API_KEY não encontrada no .env\")\n",
                "else:\n",
                "    genai.configure(api_key=api_key)\n",
                "    print(\"API Gemini configurada com sucesso!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Definição do Prompt (Engenharia de Prompt)\n",
                "Criaremos um prompt do tipo \"Few-Shot\" (ou instrução direta robusta) para garantir que o modelo extraia exatamente os campos desejados: Nome, Idade, Sintomas, Medicamentos em uso e Sinais Vitais."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_clinical_data(medical_note):\n",
                "    model = genai.GenerativeModel('gemini-pro')\n",
                "    \n",
                "    prompt = f\"\"\"\n",
                "    Atue como um especialista em processamento de dados médicos.\n",
                "    Sua tarefa é ler a anotação clínica abaixo e extrair as informações em formato JSON estrito.\n",
                "    \n",
                "    Campos obrigatórios no JSON:\n",
                "    - paciente_nome (string)\n",
                "    - idade (int, ou null se não informado)\n",
                "    - sintomas (lista de strings)\n",
                "    - medicamentos_em_uso (lista de strings)\n",
                "    - sinais_vitais (objeto com pressao_arterial, frequencia_cardiaca, temperatura - use null se não houver)\n",
                "    - risco_estimado (string: 'Baixo', 'Medio', 'Alto' - deduza pelo contexto)\n",
                "\n",
                "    ANOTAÇÃO CLÍNICA:\n",
                "    {medical_note}\n",
                "    \n",
                "    SAÍDA JSON:\n",
                "    \"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = model.generate_content(prompt)\n",
                "        # Tratamento básico para garantir que pegamos apenas o JSON caso o modelo fale algo antes\n",
                "        text_resp = response.text.replace('```json', '').replace('```', '').strip()\n",
                "        return json.loads(text_resp)\n",
                "    except Exception as e:\n",
                "        return {\"erro\": str(e), \"raw_response\": response.text if 'response' in locals() else \"\"}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Teste com Caso Simulado 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "caso_1 = \"\"\"\n",
                "Paciente Maria da Silva, 65 anos, comparece relatando forte dor no peito que irradia para o braço esquerdo, iniciada há 2 horas. \n",
                "Relata também sudorese e náusea. Nega febre. \n",
                "Faz uso contínuo de Losartana e AAS. \n",
                "Ao exame físico: PA 160/100 mmHg, FC 110 bpm, SatO2 96%.\n",
                "\"\"\"\n",
                "\n",
                "dados_1 = extract_clinical_data(caso_1)\n",
                "print(json.dumps(dados_1, indent=4, ensure_ascii=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Teste com Caso Simulado 2 (Texto mais informal)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "caso_2 = \"\"\"\n",
                "João Souza esteve aqui hoje. O rapaz tá reclamando de uma tosse seca e as vezes falta um pouco de ar quando sobe escada. \n",
                "Ele disse que não toma remédio nenhum. A pressão tava boa, 12 por 8, e o coração batendo a 75.\n",
                "\"\"\"\n",
                "\n",
                "dados_2 = extract_clinical_data(caso_2)\n",
                "print(json.dumps(dados_2, indent=4, ensure_ascii=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusão\n",
                "O modelo Gemini foi capaz de estruturar dados complexos e heterogêneos, padronizando a saída para integração com sistemas de prontuário eletrônico ou dashboards de BI."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}