{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CardioIA - Fase 4: Visao Computacional\n",
    "\n",
    "Pipeline base para pre-processamento e classificacao de imagens medicas simuladas.\n",
    "- Dataset sugerido: NIH Chest X-Ray (Kaggle) ou outro ImageFolder.\n",
    "- Inclui CNN simples (do zero) e esqueleto de transfer learning.\n",
    "- Usa FakeData quando `USE_FAKE_DATA=True` para validar o fluxo sem dataset real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante:** coloque o dataset real em `../data/raw/<dataset>/train|val|test` (estrutura ImageFolder). Defina `cfg.use_fake_data=False` e `cfg.data_dir` para o caminho correto. Se o caminho nao existir, o notebook cai em `FakeData` apenas para smoke test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config geral\n",
    "Ajuste `data_dir` para o dataset real. Se ele nao existir, define `USE_FAKE_DATA=True` para rodar o fluxo end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    data_dir: Path = Path(\"../data/raw/chest_xray\")  # ajuste para seu dataset\n",
    "    use_fake_data: bool = False  # mude para False quando o dataset real estiver baixado\n",
    "    img_size: Tuple[int, int] = (224, 224)\n",
    "    batch_size: int = 16\n",
    "    num_workers: int = 0  # Windows + notebooks: deixe 0 para evitar problemas\n",
    "    num_epochs: int = 3\n",
    "    lr: float = 1e-3\n",
    "    transfer_learning: bool = True\n",
    "    fake_classes: int = 2\n",
    "    fake_samples: int = 200\n",
    "\n",
    "\n",
    "cfg = CFG()\n",
    "cfg.data_dir = cfg.data_dir.resolve()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "- Para dataset real, espera estrutura ImageFolder: `root/class_x/xxx.png`.\n",
    "- FakeData habilita smoke test sem baixar nada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "base_transforms = transforms.Compose([\n",
    "    transforms.Resize(cfg.img_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "if cfg.use_fake_data or not cfg.data_dir.exists():\n",
    "    print(\"Usando FakeData (ajuste cfg.use_fake_data=False quando tiver dataset real).\")\n",
    "    fake_train = datasets.FakeData(\n",
    "        size=cfg.fake_samples,\n",
    "        image_size=(3, *cfg.img_size),\n",
    "        num_classes=cfg.fake_classes,\n",
    "        transform=base_transforms,\n",
    "    )\n",
    "    fake_val = datasets.FakeData(\n",
    "        size=max(20, cfg.fake_samples // 5),\n",
    "        image_size=(3, *cfg.img_size),\n",
    "        num_classes=cfg.fake_classes,\n",
    "        transform=base_transforms,\n",
    "    )\n",
    "    class_names = [str(i) for i in range(cfg.fake_classes)]\n",
    "    num_classes = cfg.fake_classes\n",
    "    train_loader = DataLoader(fake_train, batch_size=cfg.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(fake_val, batch_size=cfg.batch_size, shuffle=False)\n",
    "else:\n",
    "    train_dir = cfg.data_dir / \"train\"\n",
    "    val_dir = cfg.data_dir / \"val\"\n",
    "    if not train_dir.exists() or not val_dir.exists():\n",
    "        raise SystemExit(\"Crie pastas train/ e val/ dentro do dataset ou habilite FakeData.\")\n",
    "\n",
    "    train_ds = datasets.ImageFolder(train_dir, transform=base_transforms)\n",
    "    val_ds = datasets.ImageFolder(val_dir, transform=base_transforms)\n",
    "    class_names = train_ds.classes\n",
    "    num_classes = len(class_names)\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "num_classes, class_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1: CNN simples\n",
    "Rede pequena para baseline. Ajuste canais/filtros conforme o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def accuracy(logits, targets):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, total_acc, total_samples = 0.0, 0.0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_size = labels.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_acc += accuracy(logits, labels) * batch_size\n",
    "        total_samples += batch_size\n",
    "    return total_loss / total_samples, total_acc / total_samples\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_samples = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            batch_size = labels.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_acc += accuracy(logits, labels) * batch_size\n",
    "            total_samples += batch_size\n",
    "    return total_loss / total_samples, total_acc / total_samples\n",
    "\n",
    "\n",
    "model = SmallCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "history = []\n",
    "start = time.time()\n",
    "for epoch in range(cfg.num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    history.append({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_acc\": train_acc, \"val_loss\": val_loss, \"val_acc\": val_acc})\n",
    "    print(f\"Epoch {epoch+1}/{cfg.num_epochs} | train_loss={train_loss:.4f} acc={train_acc:.3f} | val_loss={val_loss:.4f} acc={val_acc:.3f}\")\n",
    "print(f\"Tempo total: {time.time() - start:.1f}s\")\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2: Transfer Learning (ex.: ResNet18)\n",
    "Congela os pesos do backbone e treina apenas o cabe√ßalho (head). Se nao quiser baixar pesos, passe `weights=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.transfer_learning:\n",
    "    weights = models.ResNet18_Weights.DEFAULT if hasattr(models, \"ResNet18_Weights\") else None\n",
    "    backbone = models.resnet18(weights=weights)\n",
    "    for param in backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    in_features = backbone.fc.in_features\n",
    "    backbone.fc = nn.Linear(in_features, num_classes)\n",
    "    backbone = backbone.to(device)\n",
    "\n",
    "    tl_optimizer = optim.Adam(backbone.fc.parameters(), lr=1e-3)\n",
    "    tl_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    tl_hist = []\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(backbone, train_loader, tl_criterion, tl_optimizer)\n",
    "        val_loss, val_acc = evaluate(backbone, val_loader, tl_criterion)\n",
    "        tl_hist.append({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_acc\": train_acc, \"val_loss\": val_loss, \"val_acc\": val_acc})\n",
    "        print(f\"[TL] Epoch {epoch+1}/{cfg.num_epochs} | train_loss={train_loss:.4f} acc={train_acc:.3f} | val_loss={val_loss:.4f} acc={val_acc:.3f}\")\n",
    "    tl_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximos passos\n",
    "- Salvar metricas e matriz de confusao em `FASE4/reports/`.\n",
    "- Exportar modelo (torch.save) para servir no Flask/app.\n",
    "- Adicionar notebook ou script de fairness (IR ALEMA 1).\n",
    "- Integrar com app mobile (IR ALEMA 2) consumindo um endpoint simples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
